{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19ff9d0b-d32d-4325-a19f-2ccbfa7d2dff",
    "_uuid": "9206c5863724e1af01281071e0f0ee5109ef431b"
   },
   "source": [
    "# Classifying X-Rays using CNN\n",
    "The goal is to use a model to classify X-Rays from the NIH lung x-ray dataset and Kaggle Covid-19 x-ray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f42f6560-edf0-4efb-85a6-6e945e50895b",
    "_uuid": "3300a1edbf2e8122d88093998eb503a6fab8a719"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9a342cdc-0823-490d-9a3a-a53fb7c33727",
    "_uuid": "fe804e7c294e2d290e27b037bf1ba56177abab70"
   },
   "outputs": [],
   "source": [
    "all_xray_df = pd.read_csv('Data_Entry_2017_v2020.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('data','*'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0d674a43-170f-4ca6-a9b4-edc64ab89c35",
    "_uuid": "9a1669750b7cffcae1b7a2eb4307b85472dff192"
   },
   "source": [
    "# Preprocessing Labels\n",
    "Here we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels. We have two different runs: 1.) exclude no finding 2.) include no finding. We use this process to filter out unwanted labels and get quantitative data on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d75ed03e-986d-4f3f-81af-c910d194f390",
    "_uuid": "0c5123f65edf349f8ad2e5c5f55ac484d974f5c7"
   },
   "outputs": [],
   "source": [
    "label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9ff3a04-254d-4667-b0a3-869bbd92b08b",
    "_uuid": "78b4425b0a8932bb33864b5a3712611004687a48"
   },
   "outputs": [],
   "source": [
    "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "# uncomment the line below and comment out the line above if you want to include no Finding\n",
    "#\n",
    "# all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', 'No_Finding'))\n",
    "\n",
    "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: '' if (len(x.split('|')) > 1) else x )\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        #setting binary labels for each image id 'one' if the current 'c_label', zero otherwise.\n",
    "        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
    "all_xray_df = all_xray_df[all_xray_df['Finding Labels']!='']\n",
    "\n",
    "all_xray_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "05b6c7d9-4869-40b5-a70b-53957c69f021",
    "_uuid": "64653f9f57d3a5b952f1f1a709eb70ca38761a0d"
   },
   "source": [
    "### Clean categories\n",
    "Using this method we remove labels with a minimum amount of cases. This comes in handy when removing labels that have more than one classification, or not enough images to train the model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd273e26-63ab-4d76-925d-9c1c2c1ba69c",
    "_uuid": "9f368f9ea8947d8fc1dacf3988c58b6a2bf5fffc"
   },
   "outputs": [],
   "source": [
    "# keep at least 100 cases\n",
    "MIN_CASES = 100\n",
    "all_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES]\n",
    "print('Clean Labels ({})'.format(len(all_labels)), \n",
    "      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01478f44-5beb-4a6c-aa27-77db4b9abf10",
    "_uuid": "cf071cfa49f2886d9795cdf6067a8afdafd6f458"
   },
   "outputs": [],
   "source": [
    "# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n",
    "# weight is 0.1 + number of findings\n",
    "sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\n",
    "sample_weights /= sample_weights.sum()\n",
    "all_xray_df = all_xray_df.sample(31178, weights=sample_weights)\n",
    "\n",
    "label_counts = all_xray_df['Finding Labels'].value_counts()[:]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "277caf38-f13d-4939-9eef-55efaf73020e",
    "_uuid": "cb9f18a64740580e1c541b8631d45720be5f36fe"
   },
   "outputs": [],
   "source": [
    "label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "ax1.set_xticklabels(all_labels, rotation = 90)\n",
    "ax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n",
    "_ = ax1.set_ylabel('Frequency (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a1367d63-4c7b-4e47-b19f-9a26d1f89476",
    "_uuid": "6ed6489bbd618fb419ceca2bbd8c300694f1d4ed",
    "scrolled": true
   },
   "source": [
    "# Preparing Training and Testing Data\n",
    "Here we split the data into training and validation sets and create a single vector (disease_vec) with the 0/1 outputs for the disease status (what the model will try and predict). Given the 0 and 1 outputs we will use a binary classification model to train our CNN. We felt after testing with sparse categorical accuracy, we found that our results were not great. Switching to binary our results improved drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "185ae07c-17a2-46d3-81ca-4007e88cbf86",
    "_uuid": "6f82e5ae33e1c0fcfa33ac51a26885cb5a0e6bb1"
   },
   "outputs": [],
   "source": [
    "all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5feddc96-7958-4d34-81f1-10eba94ab1b6",
    "_uuid": "8c7dc722de08243cc763d23928708f9c040bbdc6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(all_xray_df, \n",
    "                                   test_size = 0.25,\n",
    "                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\n",
    "print('train', train_df.shape[0], 'validation', valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7178cb8d-f220-4422-93ae-2469f0c97493",
    "_uuid": "0115346eb989e7eaeffa3643d05c654ec5ceb7c2"
   },
   "source": [
    "# Build Data\n",
    "We build the data generator to randomly transform our images and categorize them into training, validtaion, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "30eaf01b-8ec0-4407-9d25-f87ca1f48e8a",
    "_uuid": "b5e42124376584390e925a06c4cee564285e43b3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "IMG_SIZE = (256, 256)\n",
    "core_idg = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=10, \n",
    "                              shear_range = 0.1,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b67dc5fa-d91b-420a-aaa7-b3991313127a",
    "_uuid": "dbb93f7f8248031563ec7042d978650c0c957c1f"
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dc4d027c-f5c4-48b8-8ab6-b41971ad514f",
    "_uuid": "cc92b74f28987fee4971e60a71f74660693f4278"
   },
   "outputs": [],
   "source": [
    "train_gen = flow_from_dataframe(core_idg, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'grayscale',\n",
    "                            batch_size = 50)\n",
    "\n",
    "valid_gen = flow_from_dataframe(core_idg, valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'grayscale',\n",
    "                            batch_size = 256) # we can use much larger batches for evaluation\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "test_X, test_Y = next(flow_from_dataframe(core_idg, \n",
    "                               valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'grayscale',\n",
    "                            batch_size = 1024)) # one big batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0621048f-3d4c-4eb7-aaee-0c53f7cbf26a",
    "_uuid": "2852ef2fe07eb6d8e2caf056d1428d153afad65f"
   },
   "outputs": [],
   "source": [
    "#  This is going to display how some of our images changed using our data generator.\n",
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n",
    "                             if n_score>0.5]))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cce3c89c-4292-4092-9317-ca066d72e354",
    "_uuid": "5b0ec78f2ffa8137dce37744f38a40782aafb54d"
   },
   "source": [
    "# Creating model\n",
    "Here we build two models. One is our design, having read numerous articles online about x-ray classification. Another is a well established keras Architecture called MobileNet. We would have liked to run this on densenet121, or ResnNet, however given computing restrictions, we were not able to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "235846d4-3ef1-4888-a276-6134ad572415",
    "_uuid": "a447f8cc7274c06555849a40881fb903aca7001a"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "# UnComment this if you want to run our model \n",
    "#\n",
    "# multi_disease_model = Sequential([\n",
    "#             #Block 1\n",
    "#             Conv2D(32, 3, strides=1, padding=\"same\", activation=\"relu\", name=\"block1_conv1\", input_shape=(256,256, 1)),\n",
    "#             Conv2D(32, 3, strides=1, padding=\"same\", activation=\"relu\", name=\"block1_conv2\"),\n",
    "#             MaxPool2D(4, name=\"block1_pool\"),\n",
    "#             #Block 2\n",
    "#             Conv2D(64, 3, strides=1, padding=\"same\", activation=\"relu\", name=\"block2_conv1\"),\n",
    "#             Conv2D(64, 3, strides=1, padding=\"same\", activation=\"relu\", name=\"block2_conv2\"),\n",
    "#             MaxPool2D(2, name=\"block2_pool\"),\n",
    "#             # Block 3\n",
    "#             Conv2D(128, 5, strides=1, padding=\"same\", activation=\"relu\", name=\"block3_conv1\"),\n",
    "#             Conv2D(128, 5, strides=1, padding=\"same\", activation=\"relu\", name=\"block3_conv2\"),\n",
    "#             Conv2D(128, 5, strides=1, padding=\"same\", activation=\"relu\", name=\"block3_conv3\"),\n",
    "#             MaxPool2D(2, name=\"block3_pool\"),\n",
    "#              #Block 4\n",
    "#             Conv2D(256, 5, strides=1, padding=\"same\", activation=\"relu\", name=\"block4_conv1\"),\n",
    "#             Conv2D(256, 5, strides=1, padding=\"same\", activation=\"relu\", name=\"block4_conv2\"),\n",
    "#             Conv2D(256, 5, strides=1, padding=\"same\", activation=\"relu\", name=\"block4_conv3\")\n",
    "\n",
    "# ])\n",
    "multi_disease_model = Sequential()\n",
    "# Comment the line below if you want to run our model\n",
    "multi_disease_model.add(MobileNet(weights = None, input_shape=(256,256, 1), classes=1000))\n",
    "multi_disease_model.add(Dropout(0.5))\n",
    "multi_disease_model.add(Flatten())\n",
    "multi_disease_model.add(Dense(512, activation='relu'))\n",
    "multi_disease_model.add(Dropout(0.25))\n",
    "multi_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\n",
    "\n",
    "multi_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                           metrics = ['binary_accuracy', 'mae'])\n",
    "multi_disease_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1acd1753-dae2-440d-a9d5-f3bbebfe446f",
    "_uuid": "90a131f99bea8b77fba54024e261a97e24dfc6c1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "weight_path=\"weights/xray_weights_best.hdf5\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "# Several articles we read that classify x-rays use this callback and it helped improve their accuracy and so we decided to implement this.\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e5ad629e-15a3-4c96-ac74-db8077b101fe",
    "_uuid": "eba5247e4a767def4b4ead6e2f02f3c334edbbf0"
   },
   "source": [
    "# First Epoch\n",
    "Here we decided to test our first epoch and see that our model has progressed and learned and gives some good initial feedback to determine if the model is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c269083c-7617-4c16-8f96-353c1f3d8eef",
    "_uuid": "cbdfcf827510dfb3bdba6ab08ff60e21838d6987"
   },
   "outputs": [],
   "source": [
    "multi_disease_model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch=200,\n",
    "                                  validation_data = (test_X, test_Y), \n",
    "                                  epochs = 1, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "571df602-c0f1-4ba0-9f1e-0c9fdc10eff3",
    "_uuid": "392f3973459dcbb3fc998191baca4d047995d351"
   },
   "source": [
    "# Testing First Epoch\n",
    "Here you could see the predicted frequency of each label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d9f519ef-4b4f-4bd9-8989-643b21cb8904",
    "_uuid": "308a85cd454ad05e451ec1db99432c6fe85e8e41"
   },
   "outputs": [],
   "source": [
    "for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n",
    "    print('%s: %2.2f%%' % (c_label, s_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73a8dba1-3d8e-47ec-b945-3101ad57dcef",
    "_uuid": "0878962d872569c57b0f959751c522ae928f92e3"
   },
   "outputs": [],
   "source": [
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7a0fc649-158c-4844-9b05-f6a62214009f",
    "_uuid": "4acd4919e0ba24e2d06ef75fbb054a907a582c7a"
   },
   "source": [
    "# ROC Curves\n",
    "We can show the ROC curves for each label and believe it is a good metric to measure reliability of a binary classifier, while accuracy alone might not be the best metric for testing how well our model predicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cc076f02-0bf2-4d3f-a6ab-f192bed9e6a9",
    "_uuid": "d7168d90928d842c295c64e2446e84eb068fd391"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('barely_trained_net.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c2fe734-8f87-4537-81e0-d0ce68bc2545",
    "_uuid": "8a03574bc1f2b3441538c2408fc158324d6d23df",
    "collapsed": true
   },
   "source": [
    "# Continued Training\n",
    "we want to test how our model does after extensive training and compare our results with our first epoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "80b6ede7-052b-4fa2-ab97-bed0199db681",
    "_uuid": "0b35cd7ef77680d2aa180812622d89388b8fff63"
   },
   "outputs": [],
   "source": [
    "multi_disease_model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch = 160,\n",
    "                                  validation_data =  (test_X, test_Y), \n",
    "                                  epochs = 15, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best weights\n",
    "multi_disease_model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97dd6d26-8d12-4aa5-8544-6bde2f8200a6",
    "_uuid": "2f358c745432e497adfac31c6d97abc8b61bd0eb"
   },
   "outputs": [],
   "source": [
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e754b40-8492-4f5b-a19f-a0bfd2c9b4f4",
    "_uuid": "db77f749926ac5936e860617b22713715a69157a"
   },
   "outputs": [],
   "source": [
    "# look at how often the algorithm predicts certain diagnoses \n",
    "for c_label, p_count, t_count in zip(all_labels, \n",
    "                                     100*np.mean(pred_Y,0), \n",
    "                                     100*np.mean(test_Y,0)):\n",
    "    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "31990e46-1437-4945-aaa5-b31b377d6538",
    "_uuid": "a5dd26025391067cd0220b7502b193e5e095edbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('trained_net.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a50931b1-4d88-4b2f-93f7-ad3c9de31e5c",
    "_uuid": "8ad061d6b08b9ff383f682c35c8b55f30fb560a1"
   },
   "source": [
    "# Show a few images and associated predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "714ada59-850d-4d88-b983-2f9107f36e70",
    "_uuid": "e5191706a55a5ab8b68773d0b881aac4b020795a"
   },
   "outputs": [],
   "source": [
    "sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\n",
    "fig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\n",
    "for (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n",
    "    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n",
    "    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n",
    "                                                                  test_Y[idx]) \n",
    "                             if n_score>0.5]\n",
    "    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n",
    "                                                                  test_Y[idx], pred_Y[idx]) \n",
    "                             if (n_score>0.5) or (p_score>0.5)]\n",
    "    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n",
    "    c_ax.axis('off')\n",
    "fig.savefig('trained_img_predictions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "48aff5bd-c927-44ae-abd3-1de884969d3b",
    "_uuid": "817ed988ed86bc7941065eeac676d1b50cef5d0b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68354276-ebbb-46ca-acd6-9e8cd1354bba",
    "_uuid": "6c186e1070db679fb62a4a08e4f42a7ece925aff"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
